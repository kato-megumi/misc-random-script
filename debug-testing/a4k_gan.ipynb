{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "import math\n",
    "\n",
    "import torchvision\n",
    "from IPython.display import Image, display\n",
    "from PIL import Image\n",
    "\n",
    "# import onnx\n",
    "\n",
    "to_pil = torchvision.transforms.ToPILImage()\n",
    "to_tensor = torchvision.transforms.ToTensor()\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "class CReLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CReLU, self).__init__()\n",
    "    def forward(self, x):\n",
    "        # return torch.cat((F.relu(x), F.relu(-x)), 1)\n",
    "        return F.relu(torch.cat((x, -x), 1))\n",
    "\n",
    "def convert(c, iter, doswap=False):\n",
    "    swap = [0,2,1,3]\n",
    "    out_chan, in_chan, width, height = c.weight.shape\n",
    "    for to in range(math.ceil(out_chan/4)):\n",
    "        for ti in range(math.ceil(in_chan/4)):\n",
    "            for w in range(width):\n",
    "                for h in range(height):\n",
    "                    for i in range(min(4, in_chan)):\n",
    "                        for o in range(min(4, out_chan)):\n",
    "                            o = swap[o] if doswap else o\n",
    "                            c.weight.data[to*4+o, ti*4+i, h, w] = float(next(iter).group(0))\n",
    "        for o in range(min(4, out_chan)):\n",
    "            o = swap[o] if doswap else o\n",
    "            c.bias.data[to*4+o] = float(next(iter).group(0))\n",
    "\n",
    "def debug(*args, **kwargs):\n",
    "    if True:\n",
    "        print(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Anime4kGan(nn.Module):\n",
    "    def __init__(self, block_nums=5, channel=4, last_channel=8, second_last_channel=0, scale=2):\n",
    "        super(Anime4kGan, self).__init__()\n",
    "        body_a = []\n",
    "        body_b = []\n",
    "        body_c = []\n",
    "        self.scale = scale\n",
    "        self.block_nums = block_nums\n",
    "        self.second_last_channel = second_last_channel\n",
    "        self.first = nn.Conv2d(3, channel, kernel_size=3, padding=1)\n",
    "        for i in range(block_nums):\n",
    "            if i != self.block_nums - 1:\n",
    "                body_a.append(nn.Conv2d(channel * 2, 4, kernel_size=3, padding=1))\n",
    "            body_b.append(nn.Conv2d(channel * 2, 4, kernel_size=3, padding=1))\n",
    "            body_c.append(\n",
    "                nn.Conv2d(\n",
    "                    channel * 2 + 16 + i * 8,\n",
    "                    channel if i != block_nums - 1 else last_channel,\n",
    "                    kernel_size=1,\n",
    "                    padding=0,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.body_a = nn.ModuleList(body_a)\n",
    "        self.body_b = nn.ModuleList(body_b)\n",
    "        self.body_c = nn.ModuleList(body_c)\n",
    "        if second_last_channel == 0:\n",
    "            self.last = nn.Conv2d(last_channel * 2, 3, kernel_size=3, padding=1)\n",
    "        else:\n",
    "            self.last = nn.Conv2d(last_channel * 2, second_last_channel, kernel_size=3, padding=2, dilation=2)\n",
    "            self.second_last = nn.Conv2d(second_last_channel * 2, 3, kernel_size=3, padding=1)\n",
    "        self.crelu = CReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.first(x)\n",
    "        accumulate = []\n",
    "        for i in range(self.block_nums):\n",
    "            x0 = self.crelu(x0)\n",
    "            if i != self.block_nums - 1:\n",
    "                x2 = self.crelu(self.body_a[i](x0))\n",
    "            x1 = self.crelu(self.body_b[i](x0))\n",
    "            accumulate.append(x1)\n",
    "            x0 = self.body_c[i](torch.cat([x0, x2, *accumulate], 1))\n",
    "        out = self.last(\n",
    "            self.crelu(F.interpolate(x0, scale_factor=self.scale, mode=\"bilinear\"))\n",
    "        )\n",
    "        if self.second_last_channel > 0:\n",
    "            out = self.second_last(self.crelu(out))\n",
    "        return out + F.interpolate(x, scale_factor=self.scale, mode=\"bilinear\")\n",
    "    \n",
    "\n",
    "    def import_param(self, filename):\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = False\n",
    "        with open(filename) as f:\n",
    "            text = f.read()\n",
    "        pattern = r\"-?\\d+(\\.\\d{2,})(e-?\\d+)?\"\n",
    "        iter = re.finditer(pattern, text)\n",
    "        convert(self.first, iter)\n",
    "        for i in range(self.block_nums):\n",
    "            if i != self.block_nums - 1:\n",
    "                convert(self.body_a[i], iter)\n",
    "            convert(self.body_b[i], iter)\n",
    "            convert(self.body_c[i], iter)\n",
    "        convert(self.last, iter)\n",
    "        if self.second_last_channel > 0:\n",
    "            convert(self.second_last, iter)\n",
    "        check = next(iter, None)\n",
    "        if check == None:\n",
    "            print(\"pass\")\n",
    "        else:\n",
    "            print(\"---failed---\\n\", check)\n",
    "\n",
    "\n",
    "# model = Anime4kGan(block_nums=5, channel=8, last_channel=12, scale=2)\n",
    "# model.import_param(\"tmp/Anime4K_Upscale_GAN_x2_M.glsl\")\n",
    "\n",
    "# model = Anime4kGan(block_nums=5, channel=12, last_channel=12, second_last_channel=8, scale=3)\n",
    "# model.import_param(\"tmp/Anime4K_Upscale_GAN_x3_L.glsl\")\n",
    "\n",
    "# model = Anime4kGan(block_nums=10, channel=16, last_channel=16, second_last_channel=12, scale=4)\n",
    "# model.import_param(\"tmp/Anime4K_Upscale_GAN_x4_UL.glsl\")\n",
    "\n",
    "# model = Anime4kGan(block_nums=9, channel=24, last_channel=24, second_last_channel=24, scale=4)\n",
    "# model.import_param(\"tmp/Anime4K_Upscale_GAN_x4_UUL.glsl\")\n",
    "# model.to(device).half()\n",
    "\n",
    "# image2 = Image.open(\"/Users/khoi.ho/Downloads/Screenshot 2023-12-18 18-32-07.png\").convert(\"RGB\")\n",
    "# image2 = to_tensor(image2).unsqueeze(0).to(device).half()\n",
    "# out = model(image2)[0]\n",
    "# # clamp out to 0,1 \n",
    "# out = torch.clamp(out, min=0, max=1)\n",
    "# display(to_pil(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.randn(1, 3, 720, 1280).to(device).half()\n",
    "upscaleModel = [\n",
    "    (\"tmp/Anime4K_Upscale_GAN_x2_S.glsl\", \"Anime4K_Upscale_GAN_x2_S\", 5 , 4, 8, 0, 2),\n",
    "    (\"tmp/Anime4K_Upscale_GAN_x2_M.glsl\", \"Anime4K_Upscale_GAN_x2_M\", 5 , 8, 12, 0, 2),\n",
    "    (\"tmp/Anime4K_Upscale_GAN_x3_L.glsl\", \"Anime4K_Upscale_GAN_x3_L\",  5 , 12, 12, 8, 3),\n",
    "    (\"tmp/Anime4K_Upscale_GAN_x3_VL.glsl\", \"Anime4K_Upscale_GAN_x3_VL\", 8 , 12, 16, 12, 3),\n",
    "    (\"tmp/Anime4K_Upscale_GAN_x4_UL.glsl\", \"Anime4K_Upscale_GAN_x4_UL\", 10, 16, 16, 12, 4),\n",
    "    (\"tmp/Anime4K_Upscale_GAN_x4_UUL.glsl\", \"Anime4K_Upscale_GAN_x4_UUL\", 9, 24, 24, 24, 4),\n",
    "]\n",
    "\n",
    "for filename, name, a, b, c, d, e in upscaleModel:\n",
    "    onnx_path = f\"onnxModel/{name}.onnx\"\n",
    "    model = Anime4kGan(a, b, c, d, e)\n",
    "    model.import_param(filename)\n",
    "    model.to(device).half()\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        dummy_input,\n",
    "        onnx_path,\n",
    "        input_names=[\"input\"],\n",
    "        output_names=[\"output\"],\n",
    "        dynamic_axes={\n",
    "            \"input\": {0: \"batch_size\", 2: \"width\", 3: \"height\"},\n",
    "            \"output\": {0: \"batch_size\", 2: \"width\", 3: \"height\"},\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fvcore.nn import FlopCountAnalysis\n",
    "for filename, name, a, b, c, d, e in upscaleModel:\n",
    "    model = Anime4kGan(a, b, c, d, e).to(device).half()\n",
    "    flops = FlopCountAnalysis(model, dummy_input)\n",
    "    print(name, f': {flops.total() / 10**9:.3f}G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Anime4kGan(block_nums=5, channel=8, last_channel=12, scale=2).to(device).half()\n",
    "model = Anime4kGan(block_nums=5, channel=12, last_channel=12, second_last_channel=8, scale=3).to(device).half()\n",
    "dummy_input = torch.randn(1, 3, 720, 1280).to(device).half()\n",
    "output_tensor = model.forward(dummy_input)\n",
    "\n",
    "\n",
    "# get total number of parameters of model\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total number of parameters: {total_params:,}\")\n",
    "\n",
    "with open(\"tmp/Anime4K_Upscale_GAN_x3_L.glsl\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "pattern = r'-?\\d+(\\.\\d{3,})(e-?\\d+)?'\n",
    "# get total number of match patern in text\n",
    "total_match_pattern = len(re.findall(pattern, text))\n",
    "print(f\"Total number of match pattern: {total_match_pattern:,}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
