{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::sub encountered 7 time(s)\n",
      "Unsupported operator aten::mul encountered 7 time(s)\n",
      "Unsupported operator aten::silu_ encountered 12 time(s)\n",
      "Unsupported operator aten::sigmoid encountered 6 time(s)\n",
      "Unsupported operator aten::add encountered 6 time(s)\n",
      "Unsupported operator aten::pixel_shuffle encountered 1 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "block_1.act2, block_2.act2, block_3.act2, block_4.act2, block_5.act2, block_6.act2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": 24.717G\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def _make_pair(value):\n",
    "    if isinstance(value, int):\n",
    "        value = (value,) * 2\n",
    "    return value\n",
    "\n",
    "\n",
    "def conv_layer(in_channels,\n",
    "               out_channels,\n",
    "               kernel_size,\n",
    "               bias=True):\n",
    "    \"\"\"\n",
    "    Re-write convolution layer for adaptive `padding`.\n",
    "    \"\"\"\n",
    "    kernel_size = _make_pair(kernel_size)\n",
    "    padding = (int((kernel_size[0] - 1) / 2),\n",
    "               int((kernel_size[1] - 1) / 2))\n",
    "    return nn.Conv2d(in_channels,\n",
    "                     out_channels,\n",
    "                     kernel_size,\n",
    "                     padding=padding,\n",
    "                     bias=bias)\n",
    "\n",
    "\n",
    "def activation(act_type, inplace=True, neg_slope=0.05, n_prelu=1):\n",
    "    \"\"\"\n",
    "    Activation functions for ['relu', 'lrelu', 'prelu'].\n",
    "    Parameters\n",
    "    ----------\n",
    "    act_type: str\n",
    "        one of ['relu', 'lrelu', 'prelu'].\n",
    "    inplace: bool\n",
    "        whether to use inplace operator.\n",
    "    neg_slope: float\n",
    "        slope of negative region for `lrelu` or `prelu`.\n",
    "    n_prelu: int\n",
    "        `num_parameters` for `prelu`.\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    act_type = act_type.lower()\n",
    "    if act_type == 'relu':\n",
    "        layer = nn.ReLU(inplace)\n",
    "    elif act_type == 'lrelu':\n",
    "        layer = nn.LeakyReLU(neg_slope, inplace)\n",
    "    elif act_type == 'prelu':\n",
    "        layer = nn.PReLU(num_parameters=n_prelu, init=neg_slope)\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            'activation layer [{:s}] is not found'.format(act_type))\n",
    "    return layer\n",
    "\n",
    "\n",
    "def sequential(*args):\n",
    "    \"\"\"\n",
    "    Modules will be added to the a Sequential Container in the order they\n",
    "    are passed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    args: Definition of Modules in order.\n",
    "    -------\n",
    "    \"\"\"\n",
    "    if len(args) == 1:\n",
    "        if isinstance(args[0], OrderedDict):\n",
    "            raise NotImplementedError(\n",
    "                'sequential does not support OrderedDict input.')\n",
    "        return args[0]\n",
    "    modules = []\n",
    "    for module in args:\n",
    "        if isinstance(module, nn.Sequential):\n",
    "            for submodule in module.children():\n",
    "                modules.append(submodule)\n",
    "        elif isinstance(module, nn.Module):\n",
    "            modules.append(module)\n",
    "    return nn.Sequential(*modules)\n",
    "\n",
    "\n",
    "def pixelshuffle_block(in_channels,\n",
    "                       out_channels,\n",
    "                       upscale_factor=2,\n",
    "                       kernel_size=3):\n",
    "    \"\"\"\n",
    "    Upsample features according to `upscale_factor`.\n",
    "    \"\"\"\n",
    "    conv = conv_layer(in_channels,\n",
    "                      out_channels * (upscale_factor ** 2),\n",
    "                      kernel_size)\n",
    "    pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "    return sequential(conv, pixel_shuffle)\n",
    "\n",
    "class SPAB(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 mid_channels=None,\n",
    "                 out_channels=None,\n",
    "                 bias=False):\n",
    "        super(SPAB, self).__init__()\n",
    "        if mid_channels is None:\n",
    "            mid_channels = in_channels\n",
    "        if out_channels is None:\n",
    "            out_channels = in_channels\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.c1_r = conv_layer(in_channels, mid_channels, 3)\n",
    "        self.c2_r = conv_layer(mid_channels, mid_channels, 3)\n",
    "        self.c3_r = conv_layer(mid_channels, out_channels, 3)\n",
    "        self.act1 = torch.nn.SiLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = (self.c1_r(x))\n",
    "        out1_act = self.act1(out1)\n",
    "\n",
    "        out2 = (self.c2_r(out1_act))\n",
    "        out2_act = self.act1(out2)\n",
    "\n",
    "        out3 = (self.c3_r(out2_act))\n",
    "\n",
    "        sim_att = torch.sigmoid(out3) - 0.5\n",
    "        out = (out3 + x) * sim_att\n",
    "\n",
    "        return out, out1, sim_att\n",
    "\n",
    "class SPAN(nn.Module):\n",
    "    \"\"\"\n",
    "    Swift Parameter-free Attention Network for Efficient Super-Resolution\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_in_ch,\n",
    "                 num_out_ch,\n",
    "                 feature_channels=48,\n",
    "                 upscale=4,\n",
    "                 bias=True,\n",
    "                 img_range=255.,\n",
    "                 rgb_mean=(0.4488, 0.4371, 0.4040)\n",
    "                 ):\n",
    "        super(SPAN, self).__init__()\n",
    "\n",
    "        in_channels = num_in_ch\n",
    "        out_channels = num_out_ch\n",
    "        self.img_range = img_range\n",
    "        self.mean = torch.Tensor(rgb_mean).view(1, 3, 1, 1)\n",
    "\n",
    "        self.conv_1 = conv_layer(in_channels, feature_channels, 3)\n",
    "        self.block_1 = SPAB(feature_channels, bias=bias)\n",
    "        self.block_2 = SPAB(feature_channels, bias=bias)\n",
    "        self.block_3 = SPAB(feature_channels, bias=bias)\n",
    "        self.block_4 = SPAB(feature_channels, bias=bias)\n",
    "        self.block_5 = SPAB(feature_channels, bias=bias)\n",
    "        self.block_6 = SPAB(feature_channels, bias=bias)\n",
    "\n",
    "        self.conv_cat = conv_layer(feature_channels * 4, feature_channels, kernel_size=1, bias=True)\n",
    "        self.conv_2 = conv_layer(feature_channels, feature_channels, 3)\n",
    "\n",
    "        self.upsampler = pixelshuffle_block(feature_channels, out_channels, upscale_factor=upscale)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mean = self.mean.type_as(x)\n",
    "        x = (x - self.mean) * self.img_range\n",
    "\n",
    "        out_feature = self.conv_1(x)\n",
    "\n",
    "        out_b1, _, att1 = self.block_1(out_feature)\n",
    "        out_b2, _, att2 = self.block_2(out_b1)\n",
    "        out_b3, _, att3 = self.block_3(out_b2)\n",
    "\n",
    "        out_b4, _, att4 = self.block_4(out_b3)\n",
    "        out_b5, _, att5 = self.block_5(out_b4)\n",
    "        out_b6, out_b5_2, att6 = self.block_6(out_b5)\n",
    "\n",
    "        out_b6 = self.conv_2(out_b6)\n",
    "        out = self.conv_cat(torch.cat([out_feature, out_b6, out_b1, out_b5_2], 1))\n",
    "        output = self.upsampler(out)\n",
    "\n",
    "        return output\n",
    "\n",
    "from fvcore.nn import FlopCountAnalysis, flop_count_table\n",
    "device = torch.device(\"mps\")\n",
    "model = SPAN(3, 3, upscale=2, feature_channels=12).to(device)\n",
    "model.eval()\n",
    "inputs = (torch.rand(1, 3, 720, 1280).to(device),)\n",
    "flops = FlopCountAnalysis(model, inputs)\n",
    "print(f': {flops.total() / 10**9:.3f}G')\n",
    "# print(flop_count_table(flops))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
